{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3dac5d-d043-432d-96f2-ce0df4b219da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spark session\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a23c47a-b5c8-464d-81b6-eca54690a51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://766eb1b9a2f1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Process json from kafka</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x73356ae97fa0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Process json from kafka\")\n",
    "    .config(\"spark.sql.streaming.stopGracefullyOnShutdown\", True)\n",
    "    .config(\"spark.jars.packages\",\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", 4)\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff1594e-350d-4db6-b4a5-3e23bef80216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json data from kafka topic custords\n",
    "\n",
    "orderjson_df = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"ed-kafka:29092\")\n",
    "    .option(\"subscribe\", \"custords\")\n",
    "    .option(\"startingOffsets\", \"earliest\") #earliest/latest\n",
    "    .option(\"maxOffsetsPerTrigger\", 10000)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5966c4-4c6e-47d5-a930-afafaf5e96e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderjson_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ae30bd-ec45-4482-9a3b-2f30f57b5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#orderjson_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d40537-53ed-4191-8b11-c0eae98db90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Json values from the data for parsing and flattening\n",
    "from pyspark.sql.functions import expr, col\n",
    "\n",
    "stringjson_df = orderjson_df.withColumn(\"value\", expr(\"cast(value as string)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801fb3b9-73bb-48b0-b4c7-411c0ee1b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stringjson_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab38abf-b978-4694-810b-f220c389f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using explicit Schema mapping\n",
    "json_schema = \"\"\"\n",
    "struct<\n",
    "  event_id:string,\n",
    "  event_type:string,\n",
    "  event_timestamp:string,\n",
    "  order:struct<\n",
    "    order_id:string,\n",
    "    customer_id:string,\n",
    "    currency:string,\n",
    "    product_id:string,\n",
    "    product_name:string,\n",
    "    category:string,\n",
    "    quantity:int,\n",
    "    unit_price:int,\n",
    "    total_price:int\n",
    "  >,\n",
    "  payment:struct<\n",
    "    payment_method:string,\n",
    "    status:string,\n",
    "    transaction_id:string\n",
    "  >,\n",
    "  customer_context:struct<\n",
    "    device:string,\n",
    "    location:string,\n",
    "    ip_address:string,\n",
    "    session_id:string\n",
    "  >\n",
    ">\n",
    "\"\"\"\n",
    "from pyspark.sql.functions import from_json\n",
    "df_with_schema = stringjson_df.select(\n",
    "    from_json(col(\"value\").cast(\"string\"), json_schema).alias(\"data\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a55b52-e4a6-4d6a-876f-4ea8b1a66abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_schema.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e28aa890-df3b-4b84-8825-05ef067670c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631033e9-a786-4ef5-8279-f7d1940e1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for valid data and create a path for invalid JSON data\n",
    "valid_json = df_with_schema.filter(col(\"data\").isNotNull())\n",
    "invalid_json = df_with_schema.filter(col(\"data\").isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf994a7-3d0f-4128-90b0-867abeb492ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_json.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"checkpointLocation\", \"chk/invalid\") \\\n",
    "    .option(\"path\", \"data/dlq/invalid_json\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5441f9fc-6988-407c-8208-879422f5f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bronze_df = valid_json.select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be97a60e-9c95-4bc0-a612-30ff19cb3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bronze_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a7b15a-89ac-48ae-bbfa-890e28f7d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# get the final clean flattened data\n",
    "Bronze_df_final = Bronze_df.select(\"event_id\", \"event_type\", \"event_timestamp\", \"order.*\", \"payment.*\", \"customer_context.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c6e6d37-3545-47fd-bad5-c4f30348547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bronze_df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec9d19e8-b38a-4d9c-af64-6f95e7e43253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running in once/available now and processingTime mode\n",
    "#write the output to sink to check output\n",
    "\n",
    "(\n",
    "    Bronze_df_final\n",
    "    .writeStream\n",
    "    .format(\"console\")\n",
    "    .outputMode(\"append\")\n",
    "    .trigger(once=True) #processingTime=\"10 seconds\"\n",
    "    .option(\"checkpointLocation\", \"checkpoint_dir_custords_1\")\n",
    "    .start()\n",
    "    .awaitTermination()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9efe5a7-8fca-431c-a68e-b88c008f56ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/local/lib/python3.10/socket.py\", line 717, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#running in continuous mode\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#write the output to memory sink to check output\u001b[39;00m\n\u001b[1;32m      4\u001b[0m (\n\u001b[1;32m      5\u001b[0m     \u001b[43mBronze_df_final\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriteStream\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueryName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputMode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrigger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontinuous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m10 seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpointLocation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint_dir_custords_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m/spark/python/pyspark/sql/streaming.py:107\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#running in continuous mode\n",
    "#write the output to memory sink to check output\n",
    "\n",
    "(\n",
    "    Bronze_df_final\n",
    "    .writeStream\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"kafka_table\")\n",
    "    .outputMode(\"append\")\n",
    "    .trigger(continuous=\"10 seconds\")\n",
    "    .option(\"checkpointLocation\", \"checkpoint_dir_custords_2\")\n",
    "    .start()\n",
    "    .awaitTermination()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b1da28-e046-4f64-8904-61277247a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "\n",
    "bronze_data_write = (\n",
    "    Bronze_df_final.writeStream\n",
    "    .format(\"parquet\")     # Delta if available\n",
    "    .option(\"checkpointLocation\", \"chk/bronze\")\n",
    "    .option(\"path\", \"data/bronze/orders\")\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "634c7782-106c-4204-9670-a739056ad2f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- event_timestamp: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- unit_price: integer (nullable = true)\n",
      " |-- total_price: integer (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- device: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- session_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bronze_df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7916fe3f-b717-41c5-b3e2-c265418b0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "silver_df = (\n",
    "    Bronze_df_final\n",
    "    .withColumn(\"event_ts\", to_timestamp(\"event_timestamp\"))\n",
    "    .dropDuplicates([\"event_id\"])\n",
    "    .filter(col(\"status\") == \"PAID\")\n",
    "    .select(\n",
    "        \"event_id\",\n",
    "        \"event_type\",\n",
    "        \"event_ts\",\n",
    "        \"order_id\",\n",
    "        \"customer_id\",\n",
    "        \"product_id\",\n",
    "        \"product_name\",\n",
    "        \"category\",\n",
    "        \"quantity\",\n",
    "        \"unit_price\",\n",
    "        \"total_price\",\n",
    "        \"payment_method\",\n",
    "        \"location\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "silver_write = (\n",
    "    silver_df.writeStream\n",
    "    .format(\"parquet\")\n",
    "    .option(\"checkpointLocation\", \"chk/silver\")\n",
    "    .option(\"path\", \"data/silver/orders\")\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a908b-7a28-4cf8-b1f9-aa99cde5d1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9341659-1232-46d4-8b68-1f807ab70bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+------------+-----------+--------+----------+-------------------+-----------+--------+----------+-----------+--------------+------+--------------+-------+-----------------+---------------+--------------------+\n",
      "|            event_id|  event_type|     event_timestamp|    order_id|customer_id|currency|product_id|       product_name|   category|quantity|unit_price|total_price|payment_method|status|transaction_id| device|         location|     ip_address|          session_id|\n",
      "+--------------------+------------+--------------------+------------+-----------+--------+----------+-------------------+-----------+--------+----------+-----------+--------------+------+--------------+-------+-----------------+---------------+--------------------+\n",
      "|7bf1f8fc-c359-4ee...|ORDER_PLACED|2025-12-14T04:42:...|ORD-f21e9842|  CUST-2560|     INR|     P1002|Mechanical Keyboard|Electronics|       2|      1999|       3998|           UPI|  PAID|TXN-6ca1dd34a3|    Web|      Freemanview| 13.167.175.177|530546cb0cd84e528...|\n",
      "|cf9ade67-d1d5-401...|ORDER_PLACED|2025-12-14T04:43:...|ORD-ea60adbd|  CUST-8225|     INR|     P1005|       Office Chair|  Furniture|       2|      5999|      11998|    NetBanking|  PAID|TXN-2e9c5b7626|Android|  Lake Leslieside| 221.113.70.162|b3ec40c511e449c2a...|\n",
      "|ccdfbcad-7760-49e...|ORDER_PLACED|2025-12-14T04:43:...|ORD-d56f74eb|  CUST-3139|     INR|     P1003|      Running Shoes|   Footwear|       2|      2499|       4998|    NetBanking|  PAID|TXN-f8a4eea4e6|Android|     Hopkinsmouth| 182.252.161.25|8e05b6e90dd7481ca...|\n",
      "|9cf51c1a-c6d4-453...|ORDER_PLACED|2025-12-14T04:43:...|ORD-fd3a09ae|  CUST-3191|     INR|     P1005|       Office Chair|  Furniture|       1|      5999|       5999|    NetBanking|  PAID|TXN-35dad3915b|    iOS|       South Ryan|218.107.137.230|8fb4f71fca9e419eb...|\n",
      "|f48ce0b4-aa24-4fa...|ORDER_PLACED|2025-12-14T04:43:...|ORD-366f8fd5|  CUST-8514|     INR|     P1002|Mechanical Keyboard|Electronics|       2|      1999|       3998|          Card|  PAID|TXN-e60bdfcdc9|Android|      East Leslie|179.153.130.127|c527508dd3c249dd8...|\n",
      "|bcb2ad97-6130-4ad...|ORDER_PLACED|2025-12-14T04:43:...|ORD-43972682|  CUST-6563|     INR|     P1005|       Office Chair|  Furniture|       1|      5999|       5999|           UPI|  PAID|TXN-f4fb78c8bf|    Web| Lake Deannaburgh|  57.243.97.203|2cd10571d3b94317a...|\n",
      "|1cde147b-83b8-4b6...|ORDER_PLACED|2025-12-14T04:43:...|ORD-5373292b|  CUST-2273|     INR|     P1003|      Running Shoes|   Footwear|       1|      2499|       2499|          Card|  PAID|TXN-04a2386a6d|    Web|North Phillipfurt|  27.88.166.138|f7dcef98a2b745e29...|\n",
      "|c2d3564f-e023-479...|ORDER_PLACED|2025-12-14T04:44:...|ORD-8e341bc0|  CUST-9469|     INR|     P1001|     Wireless Mouse|Electronics|       3|       799|       2397|    NetBanking|  PAID|TXN-2e02661a55|Android|   Cassandramouth| 164.108.76.150|74034c18fb834d5c8...|\n",
      "|7395e69c-45d9-4ec...|ORDER_PLACED|2025-12-14T04:43:...|ORD-fa235008|  CUST-9927|     INR|     P1002|Mechanical Keyboard|Electronics|       1|      1999|       1999|          Card|  PAID|TXN-292b51f7a2|    Web|       South Marc|  212.65.183.18|1c602252a01442ffb...|\n",
      "|41040600-5a1f-431...|ORDER_PLACED|2025-12-14T04:43:...|ORD-657599b5|  CUST-8395|     INR|     P1005|       Office Chair|  Furniture|       2|      5999|      11998|           UPI|  PAID|TXN-fdbf364347|    iOS|        Ortizberg| 193.99.145.103|c6a468abdf2f4ebf9...|\n",
      "|32c55539-e551-4e7...|ORDER_PLACED|2025-12-14T04:43:...|ORD-89ebc29d|  CUST-5525|     INR|     P1005|       Office Chair|  Furniture|       2|      5999|      11998|           UPI|  PAID|TXN-1b9eacc9f0|    iOS|   New Arthurside|   114.58.54.59|1f73562e48a64df29...|\n",
      "|c6d5f7f6-84d5-4c6...|ORDER_PLACED|2025-12-14T04:43:...|ORD-3c4797aa|  CUST-1216|     INR|     P1004|         Coffee Mug|    Kitchen|       1|       299|        299|    NetBanking|  PAID|TXN-ec76bbb4e2|Android|       Kellymouth|213.172.207.136|3bd4b19665dd4d189...|\n",
      "|5ba55439-6418-402...|ORDER_PLACED|2025-12-14T04:43:...|ORD-e59effef|  CUST-5264|     INR|     P1003|      Running Shoes|   Footwear|       1|      2499|       2499|           UPI|  PAID|TXN-62e5a976e3|    Web|        East Sara|   15.10.75.255|7c8b216366214a00a...|\n",
      "|2c09627e-a31e-4a2...|ORDER_PLACED|2025-12-14T04:43:...|ORD-efc81738|  CUST-8765|     INR|     P1001|     Wireless Mouse|Electronics|       2|       799|       1598|    NetBanking|  PAID|TXN-ebd71cc292|    iOS|       Cherylfurt| 89.129.224.114|8d45505389cc431c8...|\n",
      "|0c2ef4e7-f686-46a...|ORDER_PLACED|2025-12-14T04:43:...|ORD-840aa783|  CUST-7958|     INR|     P1001|     Wireless Mouse|Electronics|       2|       799|       1598|          Card|  PAID|TXN-ee87b2d309|    Web|     Nicholsshire| 40.157.199.144|6e035a164dba46dfa...|\n",
      "|65a7376b-0629-47d...|ORDER_PLACED|2025-12-14T04:43:...|ORD-74a84b02|  CUST-6907|     INR|     P1003|      Running Shoes|   Footwear|       3|      2499|       7497|           UPI|  PAID|TXN-b05f595e42|    iOS|      Port Alexis|  190.33.39.173|243943bec32941e29...|\n",
      "|6502843f-e495-4d0...|ORDER_PLACED|2025-12-14T04:43:...|ORD-510610a2|  CUST-1896|     INR|     P1003|      Running Shoes|   Footwear|       1|      2499|       2499|    NetBanking|  PAID|TXN-5874a551e2|    Web|      Lindseybury|   54.16.44.168|e9cf2e37a33b4677a...|\n",
      "|f75d5359-6865-46a...|ORDER_PLACED|2025-12-14T04:43:...|ORD-22e571fa|  CUST-4581|     INR|     P1001|     Wireless Mouse|Electronics|       2|       799|       1598|          Card|  PAID|TXN-d95478cbea|    iOS|    Baileyborough|  95.66.138.137|b0ed3e26aa4b40dfb...|\n",
      "|742a0248-1459-48d...|ORDER_PLACED|2025-12-14T04:43:...|ORD-d8697873|  CUST-3051|     INR|     P1002|Mechanical Keyboard|Electronics|       2|      1999|       3998|           UPI|  PAID|TXN-8e015dd41c|    Web|         Leeburgh| 218.186.230.43|4f97f81f61fc4358b...|\n",
      "|1b800195-a0f1-4e2...|ORDER_PLACED|2025-12-14T04:43:...|ORD-c484a32c|  CUST-1008|     INR|     P1003|      Running Shoes|   Footwear|       3|      2499|       7497|          Card|  PAID|TXN-e0cde7a671|    Web|       Port Sarah| 139.193.38.249|6e8a3aa8064b45dd8...|\n",
      "+--------------------+------------+--------------------+------------+-----------+--------+----------+-------------------+-----------+--------+----------+-----------+--------------+------+--------------+-------+-----------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view data in memory sink\n",
    "\n",
    "spark.sql(\"select * from kafka_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d59b3-6099-4852-b911-b9153172899e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91461d60-8731-4d51-9be1-93d0715884a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_kafka_batch = spark.sql(\"select * from kafka_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c440162-06c8-46a2-80d3-0d4edb44aecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- event_timestamp: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- unit_price: integer (nullable = true)\n",
      " |-- total_price: integer (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- device: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- session_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_from_kafka_batch.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6c05066-96bd-4d94-a200-8f319d86d1ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|       product_name|\n",
      "+-------------------+\n",
      "|Mechanical Keyboard|\n",
      "|       Office Chair|\n",
      "|      Running Shoes|\n",
      "|     Wireless Mouse|\n",
      "|         Coffee Mug|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get distinct procuct names\n",
    "df_from_kafka_batch.select(\"product_name\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50dfa5c4-1ee2-440c-a62a-60b69bb5ceff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|       product_name|total_qty|\n",
      "+-------------------+---------+\n",
      "|     Wireless Mouse|     8209|\n",
      "|       Office Chair|     7932|\n",
      "|Mechanical Keyboard|     7928|\n",
      "|         Coffee Mug|     7881|\n",
      "|      Running Shoes|     7847|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the best sellling products by number of orders\n",
    "from pyspark.sql.functions import sum\n",
    "df_best_products = df_from_kafka_batch.selectExpr(\"product_name\", \"cast(quantity as int) as quantity\").groupBy(\"product_name\").agg(sum(\"quantity\").alias(\"total_qty\")).orderBy(col(\"total_qty\").desc())\n",
    "\n",
    "df_best_products.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d22ad58-be65-42d0-ba71-b47a5dcfea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the customers with the most spend\n",
    "\n",
    "from pyspark.sql.functions import col, sum, asc, desc\n",
    "Gold_df_1 = silver_df.selectExpr(\"customer_id\", \"cast((unit_price * quantity) as double) as order_price\")\\\n",
    ".groupBy(\"customer_id\").agg(sum(\"order_price\").alias(\"total_order_amt\")).orderBy(col(\"total_order_amt\").desc()).limit(5)\n",
    "                                                                                                                     \n",
    "#Gold_df_1.show()\n",
    "                                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f65cc6d7-3797-421d-ab7c-2b78e335464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- event_ts: timestamp (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- unit_price: integer (nullable = true)\n",
      " |-- total_price: integer (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94e94f7a-fa0e-4a79-9e0c-f01c6dd67f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window, sum\n",
    "\n",
    "gold_df_2 = (\n",
    "    silver_df.withWatermark(\"event_ts\", \"10 minutes\").groupBy(window(\"event_ts\", \"10 minutes\"),col(\"category\"))\n",
    "    .agg(sum(\"total_price\").alias(\"revenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "gold_write = (\n",
    "    gold_df_2.writeStream\n",
    "    .format(\"parquet\")\n",
    "    .option(\"checkpointLocation\", \"chk/gold\")\n",
    "    .option(\"path\", \"data/gold/revenue_by_category\")\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6979470a-4395-4c7a-b6d8-51d69ef13f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
